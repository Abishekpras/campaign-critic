{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kickstarter project web scraper\n",
    "\n",
    "This script will use parsed Web Robots data, which contains URLs for Kickstarter projects, to scrape and store the HTML content of each page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "import time\n",
    "import random\n",
    "from IPython.core.display import clear_output\n",
    "from warnings import warn\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load DataFrame containing parsed Web Robots data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load master file\n",
    "df = joblib.load('data/web_robots_data/web_robots_data_to_06-2017.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parsed features include\n",
    "\n",
    "- `name` - project's name\n",
    "- `category` - project's category as defined by Kickstarter\n",
    "- `hyperlink` - project's web page URL\n",
    "- `currency` - type of currency used for fundraising\n",
    "- `pledged` - total amount of money pledged by backers over the course of the project\n",
    "- `goal` - funding goal set by the creator\n",
    "- `location` - creator's location information\n",
    "\n",
    "Let's select the projects that only use US dollars for funding to focus on American projects, in order work with web pages written in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select US projects\n",
    "df_USD = df[df['currency'] == 'USD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the Web Robots data contains 196,000+ projects, let's select a random sample that we'll aim to scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>hyperlink</th>\n",
       "      <th>currency</th>\n",
       "      <th>pledged</th>\n",
       "      <th>goal</th>\n",
       "      <th>location</th>\n",
       "      <th>funded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88389</th>\n",
       "      <td>Help me start my cottage industry ... Bakesale...</td>\n",
       "      <td>Small Batch</td>\n",
       "      <td>https://www.kickstarter.com/projects/138529431...</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>Cape Coral, FL</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190378</th>\n",
       "      <td>The Sock Who Lost His Mate at NY Children's Th...</td>\n",
       "      <td>Musical</td>\n",
       "      <td>https://www.kickstarter.com/projects/987315242...</td>\n",
       "      <td>USD</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>Greenwich Village, Manhattan, NY</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21028</th>\n",
       "      <td>The 4 Disciples</td>\n",
       "      <td>Comic Books</td>\n",
       "      <td>https://www.kickstarter.com/projects/the4disci...</td>\n",
       "      <td>USD</td>\n",
       "      <td>165.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>Rahway, NJ</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name     category  \\\n",
       "88389   Help me start my cottage industry ... Bakesale...  Small Batch   \n",
       "190378  The Sock Who Lost His Mate at NY Children's Th...      Musical   \n",
       "21028                                     The 4 Disciples  Comic Books   \n",
       "\n",
       "                                                hyperlink currency  pledged  \\\n",
       "88389   https://www.kickstarter.com/projects/138529431...      USD      0.0   \n",
       "190378  https://www.kickstarter.com/projects/987315242...      USD   2600.0   \n",
       "21028   https://www.kickstarter.com/projects/the4disci...      USD    165.0   \n",
       "\n",
       "           goal                          location  funded  \n",
       "88389   10000.0                    Cape Coral, FL   False  \n",
       "190378   7000.0  Greenwich Village, Manhattan, NY   False  \n",
       "21028    2200.0                        Rahway, NJ   False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a random sample of the Web Robots data using a seed value to ensure\n",
    "# repeatability\n",
    "seed = np.random.seed(42)\n",
    "df_sample = df_USD.sample(50000)\n",
    "\n",
    "# Display the first five rows\n",
    "df_sample.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the scraping process, let's monitor the progress and measure how fast we're scraping to avoid overloading the Kickstarter server. Afterwards, we'll report total run time, the average scraping speed and total number of scraped  pages. We'll also keep track of the position of the last scraped page, in case the scraper breaks or stops for any reason, to see where we left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request: 4; Row ID: 46223; Frequency: 0.3008067836360539 requests/sec\n",
      "\n",
      "Run time: 9.980847835540771\n",
      "Average rate: 0.3005756674615666\n",
      "# of projects scraped: 3\n"
     ]
    }
   ],
   "source": [
    "# Initalize an empty DataFrame to store scraped HTML\n",
    "scraped_collection = pd.DataFrame(columns=['scraped_HTML'])\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialize the number of requests\n",
    "request_count = 0\n",
    "\n",
    "# Select which projects to scrape via its index. This is used for starting\n",
    "# at position other than the beginning in case the scraper stops unexpectedly.\n",
    "# Note that ending_point is NOT inclusive!\n",
    "starting_point = 2\n",
    "ending_point = 5\n",
    "\n",
    "# Perform web scraping\n",
    "for index, row in df_sample[starting_point:ending_point].iterrows():\n",
    "    # Perform a request and timeout if it exceeds 6 seconds\n",
    "    scraped_html = requests.get(row['hyperlink'], timeout=6)\n",
    "    \n",
    "    # Pause the loop for a random amount of time\n",
    "    time.sleep(random.uniform(2, 4))\n",
    "    \n",
    "    # Monitor the requests and display current progress\n",
    "    elapsed_time = time.time() - start_time\n",
    "    clear_output(wait = True)\n",
    "    print(\n",
    "        'Request: {}; Row ID: {}; Frequency: {} requests/sec'.format(\n",
    "            request_count + starting_point,\n",
    "            index,\n",
    "            (request_count + 1) / elapsed_time\n",
    "        )\n",
    "    )\n",
    "    request_count += 1\n",
    "    \n",
    "    # Add scraped HTML for the current project\n",
    "    scraped_collection.loc[index, 'scraped_HTML'] = scraped_html\n",
    "    \n",
    "# Display the overall time, average scraping speed and total number of scraped\n",
    "# pages\n",
    "run_time = time.time() - start_time\n",
    "print()\n",
    "print('Run time:', run_time)\n",
    "print('Average rate:', len(scraped_collection) / run_time)\n",
    "print('# of projects scraped:', len(scraped_collection))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the scraped HTML for each project page and label the filename with the indices of the projects scraped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scraped_collection_2-4.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Serialize the data table containing the scraped HTML for each project\n",
    "joblib.dump(\n",
    "    scraped_collection, 'scraped_collection_{}-{}.pkl'.format(\n",
    "        starting_point,\n",
    "        ending_point - 1\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
